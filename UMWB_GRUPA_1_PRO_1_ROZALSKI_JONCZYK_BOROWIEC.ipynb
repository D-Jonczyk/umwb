{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "592b2d7f-6ec1-4f1f-974f-7ed4ac5ee528",
   "metadata": {},
   "source": [
    "# Uczenie maszynowe w bezpieczeństwie\n",
    "\n",
    "## Projekt 1\n",
    "\n",
    "### Autorzy: Kamil Różalski, Daniel Jończyk, Dominik Borowiec\n",
    "\n",
    "### Grupa 2ID24A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d482b3b8-29f9-4a3f-b997-eddfcb8bdfb1",
   "metadata": {},
   "source": [
    "### Zadanie 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9cb7f7-36d5-40d3-8e9f-995f9ba1cbce",
   "metadata": {},
   "source": [
    "> Pobrać, rozpakować i przeanalizować strukturę plików i katalogów archiwum zawierającego wiadomości poczty elektronicznej. Dane te dostępne są pod adresem:\n",
    "> https://plg.uwaterloo.ca/~gvcormac/treccorpus07/\n",
    "> Uwaga. Nie należy otwierać plików z archiwum ani w przeglądarce HTML ani w programie pocztowym!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033f707a-c827-4aca-90c9-c5b8e8623d34",
   "metadata": {},
   "source": [
    "W pierwszym zadaniu zajęliśmy się procesem ściągania, dekompresji i analizy archiwum e-mailowego, dostępnego pod adresem https://plg.uwaterloo.ca/~gvcormac/treccorpus07/.\n",
    "\n",
    "Początkowo, po ściągnięciu archiwum, użyliśmy odpowiednich narzędzi do jego rozpakowania, co pozwoliło nam na dokładne przeanalizowanie struktury zawartości folderów w celu zrozumienia ich organizacji. Wewnątrz archiwum znaleźliśmy liczne pliki, które zawierały treści wiadomości e-mailowych.\n",
    "\n",
    "Struktura archiwum była podzielona na główne katalogi takie jak data, delay, full i partial, które zawierały różne segmenty wiadomości.\n",
    "\n",
    "Aby dokładniej zbadać dane, w kolejnych etapach moglibyśmy zastosować metody i techniki przetwarzania języka naturalnego (NLP) do wydobywania kluczowych informacji, klasyfikowania treści oraz analizowania tendencji w komunikacji mailowej."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d240f5-f912-43f1-b0bf-8440c2101af7",
   "metadata": {},
   "source": [
    "### Zadanie 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057973b8-1c83-4d5c-94d0-f133b0cd750a",
   "metadata": {},
   "source": [
    "> Wykorzystując informacje z wykładu oraz stosując technikę zakazanych słów kluczowych (blacklist), dokonać klasyfikacji binarnej wiadomości z archiwum z podziałem na: spam (wiadomości typu spam) oraz ham (wiadomości pożądane).\n",
    "Uwagi:\n",
    "> 1. Przed przystąpieniem do procesu klasyfikacji usunąć z wiadomości stopping words (np. the, is, are, . . . ),\n",
    "dokonać stemizacji słów w wiadomościach oraz ekstrakcji tokenów.\n",
    "> 2. Do realizacji zadania użyć języka Python oraz bibliotek: string, email, NLTK, os.\n",
    "> 3. Zbiór zakazanych słów kluczowych powinien być wygenerowany na podstawie danych z podzbioru treningowego,\n",
    "natomiast ewaluacja danych uzyskanych z podzbioru testowego.\n",
    "> 4. Wynikiem ewaluacji powinna być macierz konfuzji (procentowa) oraz wartość wskaźnika accuracy, również w\n",
    "postaci procentowej."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9510871b-1f63-4c89-ad93-a3b910c37e1c",
   "metadata": {},
   "source": [
    "W ramach drugiego zadania skupiliśmy się na klasyfikacji binarnej wiadomości e-mail na podstawie technik prezentowanych w wykładzie, szczególnie koncentrując się na technice zakazanych słów kluczowych (blacklist). Celem było oddzielenie wiadomości typu spam od tych pożądanych (ham).\n",
    "\n",
    "Na początku procesu klasyfikacji przeprowadziliśmy kilka kluczowych operacji przetwarzania tekstu na danych wiadomościach. Usunęliśmy z nich stopping words, co pozwoliło zredukować zakłócenia w analizie i skupienie na istotnych elementach treści. Następnie dokonaliśmy stemizacji słów, co jest procesem redukcji słów do ich korzeni, oraz ekstrahowaliśmy tokeny, co umożliwiło efektywniejszą analizę i przetwarzanie tekstu.\n",
    "\n",
    "Do implementacji tego zadania użyliśmy języka Python wraz z bibliotekami takimi jak string, email, NLTK, i os, które są niezbędne do przetwarzania i analizy tekstu. Blacklist, czyli lista zakazanych słów kluczowych, została utworzona na podstawie analizy podzbioru treningowego, co pozwoliło na adekwatne dostosowanie modelu do rzeczywistego charakteru danych."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18de82b7-6f8d-439d-b685-4aea1bdf4a4d",
   "metadata": {},
   "source": [
    "#### Implementacja"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d68b41-2c66-47cb-9df9-cb2bd1104c22",
   "metadata": {},
   "source": [
    "```python\n",
    "import os\n",
    "import re\n",
    "from collections import Counter\n",
    "from email import message_from_bytes\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "# Inicjalizacja stemizera i pobranie listy stopping words\n",
    "stemmer = PorterStemmer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2430af4-3166-4638-b324-a3b5da89dee2",
   "metadata": {},
   "source": [
    "#### Wczytywanie i przetwarzanie e-maili\n",
    "\n",
    "Funkcja load_and_preprocess_email odczytuje pliki e-mail w formacie binarnym, dekoduje ich zawartość, usuwa znaki interpunkcyjne, konwertuje tekst na małe litery, tokenizuje, usuwa stopping words oraz stemizuje.\n",
    "\n",
    "\n",
    "#### Wczytywanie etykiet\n",
    "\n",
    "Funkcja load_labels wczytuje etykiety z pliku, mapując ścieżki wiadomości na etykiety ham (0) lub spam (1)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef38aed0-a475-4f07-9928-678876c6b065",
   "metadata": {},
   "source": [
    "```python\n",
    "# Funkcja do wczytywania e-maili i ich przetwarzania\n",
    "def load_and_preprocess_email(file_path):\n",
    "    with open(file_path, 'rb') as file:  # zmienione na 'rb' do odczytu binarnego\n",
    "        email_content = message_from_bytes(file.read())\n",
    "        # Sprawdzenie, czy treść e-maila jest wieloczęściowa\n",
    "        if email_content.is_multipart():\n",
    "            email_body = ' '.join(part.get_payload(decode=True).decode('utf-8', errors='ignore')\n",
    "                                  for part in email_content.walk()\n",
    "                                  if part.get_content_type() == 'text/plain')\n",
    "        else:\n",
    "            email_body = email_content.get_payload(decode=True).decode('utf-8', errors='ignore')\n",
    "        # Usunięcie znaków interpunkcyjnych i konwersja na małe litery\n",
    "        email_body = re.sub(r'[^\\w\\s]', '', email_body).lower()\n",
    "        # Tokenizacja\n",
    "        tokens = word_tokenize(email_body)\n",
    "        # Usunięcie stopping words i stemizacja\n",
    "        filtered_tokens = [stemmer.stem(word) for word in tokens if word not in stop_words]\n",
    "        return ' '.join(filtered_tokens)\n",
    "\n",
    "\n",
    "# Funkcja do wczytywania etykiet\n",
    "def load_labels(label_file_path):\n",
    "    labels = {}\n",
    "    with open(label_file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            label, message_path = line.strip().split(' ')\n",
    "            message_id = os.path.basename(message_path)\n",
    "            labels[message_id] = 0 if label == 'ham' else 1\n",
    "    return labels\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395e40e1-b2c9-4e86-88d4-10bb1d2e6914",
   "metadata": {},
   "source": [
    "Kod wczytuje etykiety i przetwarza e-maile, następnie dzieli dane na zbiory treningowy i testowy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca59577-97a1-4835-b53f-d767d4be7f9f",
   "metadata": {},
   "source": [
    "```python\n",
    "# Ścieżki do folderów i plików\n",
    "data_dir = 'trec07p/data'\n",
    "index_file = 'trec07p/full/index'\n",
    "\n",
    "# Wczytanie etykiet\n",
    "labels = load_labels(index_file)\n",
    "\n",
    "# Wczytanie i przetwarzanie e-maili\n",
    "emails = []\n",
    "y = []\n",
    "for file_name in os.listdir(data_dir):\n",
    "    file_path = os.path.join(data_dir, file_name)\n",
    "    if file_name in labels:\n",
    "        emails.append(load_and_preprocess_email(file_path))\n",
    "        y.append(labels[file_name])\n",
    "\n",
    "# Podział na zbiory treningowy i testowy\n",
    "X_train, X_test, y_train, y_test = train_test_split(emails, y, test_size=0.2, random_state=42)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ef7bb1-9fe7-413c-a19b-8e6e1bc9908d",
   "metadata": {},
   "source": [
    "Użycie CountVectorizer do transformacji tekstu na wektory cech, a następnie klasyfikacja za pomocą MultinomialNB.\n",
    "\n",
    "Model jest ewaluowany za pomocą macierzy konfuzji i wskaźnika accuracy, które dostarczają informacji o skuteczności modelu."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5924e7-50ac-4a92-8fed-cdff89548322",
   "metadata": {},
   "source": [
    "```python\n",
    "# Tworzenie wektora cech za pomocą CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_counts = vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Klasyfikacja za pomocą MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_counts, y_train)\n",
    "X_test_counts = vectorizer.transform(X_test)\n",
    "y_pred = clf.predict(X_test_counts)\n",
    "\n",
    "# Ewaluacja modelu\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f'Macierz konfuzji:\\n{cm}')\n",
    "print(f'Wartość wskaźnika accuracy: {acc * 100:.2f}%')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25005695-41ad-4fa4-b183-623894d40c43",
   "metadata": {},
   "source": [
    "#### Podsumowanie"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5be1dec-922f-466c-afcf-73b57b7872f6",
   "metadata": {},
   "source": [
    "Kod z powodzeniem przetwarza i klasyfikuje e-maile na spam i ham wykorzystując technikę zakazanych słów kluczowych oraz zestaw operacji przetwarzania tekstu. Po dokładnym przetworzeniu danych, treningu i testowaniu modelu klasyfikacyjnego, uzyskano następujące wyniki:\n",
    "\n",
    "    Macierz konfuzji:\n",
    "        Prawdziwie pozytywne (True Positives, TP) dla wiadomości ham: 4851\n",
    "        Fałszywie negatywne (False Negatives, FN) dla wiadomości ham: 151\n",
    "        Prawdziwie pozytywne (TP) dla wiadomości spam: 9820\n",
    "        Fałszywie pozytywne (False Positives, FP) dla wiadomości spam: 262\n",
    "\n",
    "    Wartość wskaźnika accuracy: 97.26%\n",
    "\n",
    "Wysoki wynik accuracy wskazuje na skuteczność modelu w rozróżnianiu między spamem a pożądanymi wiadomościami. Macierz konfuzji również demonstruje, że model ma dobrą zdolność do poprawnego identyfikowania zarówno spamu, jak i hamu, choć zauważalna jest niewielka tendencja do błędnego klasyfikowania nielicznych wiadomości ham jako spam."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73872db1-ec0e-434d-8a66-6081a1f82e32",
   "metadata": {},
   "source": [
    "### Zadanie 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f51ef27-b859-44df-9d4a-8a07f46dfe19",
   "metadata": {},
   "source": [
    "> Zweryfikować wpływ stemizacji na pracę algorytmu zadania drugiego a następnie porównać uzyskane wyniki."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8597bc-177d-47ee-86cf-072ce4957f08",
   "metadata": {},
   "source": [
    "Do wykonania zadania zmodyfikowano istniejący kod z zadania drugiego, dodając możliwość opcjonalnego użycia stemizacji w procesie przetwarzania e-maili. Następnie porównano wyniki uzyskane z użyciem stemizacji i bez niej, aby ocenić, jak stemizacja wpływa na dokładność klasyfikacji."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708609b9-e9e2-46e0-870e-1d1344211ae0",
   "metadata": {},
   "source": [
    "#### Implementacja\n",
    "\n",
    "Kod składa się z kilku kluczowych części, które umożliwiają wczytywanie, przetwarzanie i klasyfikację danych e-mailowych. Poniżej opisano szczegółowo każdą funkcję oraz jej kluczowe parametry."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac6e907-6d65-4d17-bcf8-0c0f0abba0f7",
   "metadata": {},
   "source": [
    "```python\n",
    "import os\n",
    "import re\n",
    "from email import message_from_bytes\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "# Inicjalizacja stemizera i pobranie listy stopping words\n",
    "stemmer = PorterStemmer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d99c69-5ef2-4981-9b2a-932749e37d4b",
   "metadata": {},
   "source": [
    "**load_and_preprocess_email(file_path, use_stemming=False)**\n",
    "\n",
    "    Parametry:\n",
    "        file_path: ścieżka do pliku e-mail.\n",
    "        use_stemming: flaga decydująca o użyciu stemizacji (domyślnie wyłączona).\n",
    "    Opis: Funkcja wczytuje e-mail, dekoduje jego zawartość, usuwa znaki interpunkcyjne, konwertuje tekst na małe litery, tokenizuje go, opcjonalnie stosuje stemizację i filtruje stopping words. Zwraca przetworzony tekst jako ciąg tokenów.\n",
    "\n",
    "**load_labels(label_file_path)**\n",
    "\n",
    "    Parametry:\n",
    "        label_file_path: ścieżka do pliku z etykietami.\n",
    "    Opis: Funkcja wczytuje etykiety z pliku, przyporządkowując każdej wiadomości etykietę 0 (ham) lub 1 (spam) na podstawie ścieżki do pliku e-mail."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4a08cf-ea18-4910-b4ab-1d37477a8a77",
   "metadata": {},
   "source": [
    "```python\n",
    "# Funkcja do wczytywania e-maili i ich przetwarzania\n",
    "def load_and_preprocess_email(file_path, use_stemming=False):\n",
    "    with open(file_path, 'rb') as file:\n",
    "        email_content = message_from_bytes(file.read())\n",
    "        if email_content.is_multipart():\n",
    "            email_body = ' '.join(part.get_payload(decode=True).decode('utf-8', errors='ignore') \n",
    "                                  for part in email_content.walk() \n",
    "                                  if part.get_content_type() == 'text/plain')\n",
    "        else:\n",
    "            email_body = email_content.get_payload(decode=True).decode('utf-8', errors='ignore')\n",
    "        email_body = re.sub(r'[^\\w\\s]', '', email_body).lower()\n",
    "        tokens = word_tokenize(email_body)\n",
    "        if use_stemming:\n",
    "            filtered_tokens = [stemmer.stem(word) for word in tokens if word not in stop_words]\n",
    "        else:\n",
    "            filtered_tokens = [word for word in tokens if word not in stop_words]\n",
    "        return ' '.join(filtered_tokens)\n",
    "\n",
    "# Funkcja do wczytywania etykiet\n",
    "def load_labels(label_file_path):\n",
    "    labels = {}\n",
    "    with open(label_file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            label, message_path = line.strip().split(' ')\n",
    "            message_id = os.path.basename(message_path)\n",
    "            labels[message_id] = 0 if label == 'ham' else 1\n",
    "    return labels\n",
    "\n",
    "# Ścieżki do folderów i plików\n",
    "data_dir = 'trec07p/data'\n",
    "index_file = 'trec07p/full/index'\n",
    "\n",
    "# Wczytanie etykiet\n",
    "labels = load_labels(index_file)\n",
    "\n",
    "# Wczytanie i przetwarzanie e-maili\n",
    "emails = []\n",
    "y = []\n",
    "for file_name in os.listdir(data_dir):\n",
    "    file_path = os.path.join(data_dir, file_name)\n",
    "    if file_name in labels:\n",
    "        emails.append(load_and_preprocess_email(file_path, use_stemming=False))\n",
    "        y.append(labels[file_name])\n",
    "\n",
    "# Podział na zbiory treningowy i testowy\n",
    "X_train, X_test, y_train, y_test = train_test_split(emails, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Tworzenie wektora cech za pomocą CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_counts = vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Klasyfikacja za pomocą MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_counts, y_train)\n",
    "X_test_counts = vectorizer.transform(X_test)\n",
    "y_pred = clf.predict(X_test_counts)\n",
    "\n",
    "# Ewaluacja modelu\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f'Macierz konfuzji:\\n{cm}')\n",
    "print(f'Wartość wskaźnika accuracy: {acc * 100:.2f}%')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07882dab-4475-4e7e-a27e-6b07373ebeaa",
   "metadata": {},
   "source": [
    "#### Wyniki\n",
    "\n",
    "Otrzymane wyniki z tego eksperymentu są następujące:\n",
    "\n",
    "    Macierz konfuzji:\n",
    "        Prawdziwie pozytywne dla ham: 4854\n",
    "        Fałszywie pozytywne dla ham: 148\n",
    "        Prawdziwie pozytywne dla spam: 9805\n",
    "        Fałszywie pozytywne dla spam: 277\n",
    "    Wartość wskaźnika accuracy: 97.18%\n",
    "\n",
    "#### Podsumowanie\n",
    "\n",
    "Wprowadzenie opcji stemizacji nie przyniosło znaczącej poprawy dokładności klasyfikacji. Wynik accuracy zmniejszył się nieznacznie z 97.26% do 97.18%. Oznacza to, że dla tego konkretnego zestawu danych i zastosowanego algorytmu, stemizacja nie miała istotnego wpływu na poprawę wyników, a nawet mogła nieznacznie pogorszyć skuteczność klasyfikacji. Wynika to prawdopodobnie z faktu, że redukcja słów do ich korzeni mogła spowodować utratę pewnych niuansów językowych, które są istotne w kontekście rozróżniania spamu od pożądanych wiadomości. Może to sugerować, że dla bardziej złożonych analiz językowych, pełne formy słów mogą dostarczać cenniejszych informacji niż ich zredukowane wersje."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768fc3e1-08bc-44c7-8d7c-7f230b12f0e5",
   "metadata": {},
   "source": [
    "### Zadanie 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30fa3bc3-e8c4-4080-a6d0-9329c567d7d1",
   "metadata": {},
   "source": [
    "> Dokonać klasyfikacji binarnej wiadomości z archiwum (zadanie 1) na spam i ham, stosując algorytmy rozmytego haszowania.\n",
    "Uwagi:\n",
    "> 1. Do tego celu użyć algorytmu LSH (MinHash, MinHashLSH) z biblioteki datasketch.\n",
    "> 2. Wyniki pracy algorytmu przedstawić przy pomocy procentowej macierzy konfuzji i wskaźnika accuracy.\n",
    "> 3. Sprawdzić pracę programu dla różnych wartości parametru threshold funkcji MinHashLSH.\n",
    "> 4. Porównać uzyskane wyniki z wynikami z poprzednich zadań."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb1fbfe-cbf6-4bdb-b90c-6968b62a8b95",
   "metadata": {},
   "source": [
    "Zadanie koncentruje się na klasyfikacji binarnej wiadomości e-mail na spam i ham przy użyciu algorytmów rozmytego haszowania, specyficznie przez implementację algorytmu LSH (Locality-Sensitive Hashing) z wykorzystaniem MinHash z biblioteki datasketch. Celem jest zbadanie, jak różne wartości progu (threshold) wpływają na wyniki klasyfikacji i porównanie tych wyników z rezultatami uzyskanymi w poprzednich zadaniach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56704d4b-ead5-4c9a-8114-60a4bedd3350",
   "metadata": {},
   "source": [
    "#### Implementacja"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52fd262b-bf64-4ec3-bb22-a845f88b23fb",
   "metadata": {},
   "source": [
    "```python\n",
    "import os\n",
    "import re\n",
    "from datasketch import MinHash, MinHashLSH\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "# Inicjalizacja listy stopping words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Funkcja do wczytywania e-maili i ich przetwarzania\n",
    "def preprocess_email(email_content):\n",
    "    # Usunięcie znaków interpunkcyjnych i konwersja na małe litery\n",
    "    email_body = re.sub(r'[^\\w\\s]', '', email_content).lower()\n",
    "    # Tokenizacja\n",
    "    tokens = word_tokenize(email_body)\n",
    "    # Usunięcie stopping words\n",
    "    filtered_tokens = [word for word in tokens if word not in stop_words]\n",
    "    return filtered_tokens\n",
    "\n",
    "# Funkcja do wczytywania etykiet\n",
    "def load_labels(label_file_path):\n",
    "    labels = {}\n",
    "    with open(label_file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            label, message_path = line.strip().split(' ')\n",
    "            message_id = os.path.basename(message_path)\n",
    "            labels[message_id] = 0 if label == 'ham' else 1\n",
    "    return labels\n",
    "\n",
    "# Ścieżki do folderów i plików\n",
    "data_dir = 'trec07p/data'\n",
    "index_file = 'trec07p/full/index'\n",
    "\n",
    "# Wczytanie etykiet\n",
    "labels = load_labels(index_file)\n",
    "\n",
    "# Wczytanie i przetwarzanie e-maili\n",
    "emails = []\n",
    "y = []\n",
    "for file_name in os.listdir(data_dir):\n",
    "    file_path = os.path.join(data_dir, file_name)\n",
    "    if file_name in labels:\n",
    "        with open(file_path, 'r', encoding='utf-8', errors='ignore') as file:\n",
    "            email_content = file.read()\n",
    "        emails.append(preprocess_email(email_content))\n",
    "        y.append(labels[file_name])\n",
    "\n",
    "# Podział na zbiory treningowy i testowy\n",
    "X_train, X_test, y_train, y_test = train_test_split(emails, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Inicjalizacja LSH\n",
    "lsh = MinHashLSH(threshold=0.5, num_perm=128)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de4d2a6-ea7e-433c-b457-386c512b430f",
   "metadata": {},
   "source": [
    "W zadaniu 4 każdy przetworzony email jest konwertowany na sygnaturę MinHash przed dodaniem do struktury LSH. Jest to kluczowe dla działania algorytmu rozmytego haszowania, które polega na porównywaniu sygnatur hashujących, aby szybko znaleźć podobne obiekty:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d877cb71-2706-485e-a0eb-b471ce0a2007",
   "metadata": {},
   "source": [
    "```python\n",
    "# Tworzenie sygnatur MinHash dla e-maili i dodawanie do LSH\n",
    "for i, email_tokens in enumerate(X_train):\n",
    "    m = MinHash(num_perm=128)\n",
    "    for token in email_tokens:\n",
    "        m.update(token.encode('utf-8'))\n",
    "    lsh.insert(str(i), m)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6d612e-0fd4-4843-a57b-93026aa56583",
   "metadata": {},
   "source": [
    "#### Zmodyfikowana funkcja klasyfikacji\n",
    "\n",
    "Funkcja classify_email używa LSH do wyszukiwania podobnych e-maili na podstawie ich sygnatur MinHash. Klasyfikuje e-mail jako ham (0) lub spam (1) na podstawie najczęściej występujących etykiet wśród podobnych e-maili. To stanowi zasadniczą różnicę w podejściu do klasyfikacji w porównaniu do wcześniejszych zadań, gdzie używano bezpośrednio modeli klasyfikacyjnych z sklearn:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92abc15-1267-412d-99a0-31f774ea92f4",
   "metadata": {},
   "source": [
    "```python\n",
    "# Klasyfikacja e-maili\n",
    "def classify_email(email_tokens, lsh):\n",
    "    m = MinHash(num_perm=128)\n",
    "    for token in email_tokens:\n",
    "        m.update(token.encode('utf-8'))\n",
    "    matches = lsh.query(m)\n",
    "    if matches:\n",
    "        # Jeśli istnieją podobne e-maile, sprawdź ich etykiety\n",
    "        labels = [y_train[int(match)] for match in matches]\n",
    "        return max(set(labels), key=labels.count)\n",
    "    else:\n",
    "        return 0  # Domyślnie klasyfikuj jako ham, jeśli nie ma podobnych\n",
    "\n",
    "# Klasyfikacja zbioru testowego\n",
    "y_pred = [classify_email(email, lsh) for email in X_test]\n",
    "\n",
    "# Ewaluacja modelu\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f'Macierz konfuzji:\\n{cm}')\n",
    "print(f'Wartość wskaźnika accuracy: {acc * 100:.2f}%')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db05592-1f03-4862-9f46-393e28ca232b",
   "metadata": {},
   "source": [
    "#### Wyniki\n",
    "\n",
    "Macierz konfuzji:\n",
    "[[4992   10]\n",
    " [1679 8403]]\n",
    "Wartość wskaźnika accuracy: 88.80%\n",
    "\n",
    "\n",
    "#### Podsumowanie\n",
    "\n",
    "    - Model wykazał bardzo wysoką skuteczność w identyfikacji wiadomości pożądanych (ham), z bardzo niskim poziomem fałszywych pozytywów (FP), co stanowi zaledwie 10 przypadków na 5002. Oznacza to, że tylko nieliczne pożądane wiadomości zostały błędnie zaklasyfikowane jako spam.\n",
    "\n",
    "    - Widać znaczne wyzwanie w poprawnym klasyfikowaniu wiadomości jako spam, co manifestuje się liczbą 1679 fałszywie negatywnych wyników. Oznacza to, że te wiadomości, które były spamem, nie zostały prawidłowo zidentyfikowane przez model.\n",
    "\n",
    "    - Wskaźnik accuracy wynoszący 88.80% wskazuje na stosunkowo dobry ogólny poziom klasyfikacji. Jednakże, duża liczba fałszywie negatywnych wyników dla spamu obniża skuteczność modelu w zapewnieniu ochrony przed niechcianymi wiadomościami.\n",
    "\n",
    "    Implementacja algorytmu LSH z MinHash pokazała, że podejście to może być skuteczne w redukowaniu fałszywych alarmów (klasyfikacja ham jako spam), ale ma problemy z efektywnym wykrywaniem wszystkich przypadków spamu. Wynik ten sugeruje, że wartość progu dla LSH może potrzebować dostosowania, aby zrównoważyć pomiędzy minimalizacją fałszywych negatywów a utrzymaniem niskiego poziomu fałszywych pozytywów. Możliwe, że bardziej rygorystyczne ustawienie progu pomogłoby w lepszym wykrywaniu spamu, ale mogłoby to równocześnie zwiększyć ryzyko błędnej klasyfikacji ham jako spam."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254cb0b6-84cf-4b8d-953f-d211a01c8daf",
   "metadata": {},
   "source": [
    "### Zadanie 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8b31ec-940c-4e0d-8318-d58dc7e55e9e",
   "metadata": {},
   "source": [
    "> Dokonać klasyfikacji binarnej wiadomości z archiwum (zadanie 1) na spam i ham, stosując algorytm Naive Bayes.\n",
    "Uwagi:\n",
    "> 1. Do realizacji zadania należy użyć implementacji algorytmu z biblioteki Scikit-learn. Algorytm dostępny jest\n",
    "poprzez obiekt MultinomialNB.\n",
    "> 2. Porównać działanie algorytmu dla przypadków:\n",
    "• algorytm pracuje na całych tematach i ciele wiadomości w postaci zwykłego tekstu bez usuwania słów\n",
    "przestankowych i stemizacji przy pomocy narzędzi z biblioteki NLTK.\n",
    "• algorytm pracuje na bazie stemizowanych danych z usuniętymi słowami przestankowymi.\n",
    "> 3. Uzyskane wyniki przedstawić przy pomocy macierzy konfuzji i wskaźnika accuracy.\n",
    "> 4. Porównać uzyskane wyniki do wyników uzyskanych przy zastosowaniu metod z poprzednich zadań."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f32a7e3-f704-404e-9e09-4a51db868a87",
   "metadata": {},
   "source": [
    "Zadanie 5 koncentruje się na klasyfikacji binarnej wiadomości e-mail na spam i ham, wykorzystując algorytm Naive Bayes z biblioteki Scikit-learn. Celem zadania jest porównanie efektywności algorytmu działającego na danych w dwóch różnych formatach: zwykły tekst z całych wiadomości oraz tekst po przetworzeniu (usunięcie słów przestankowych i stemizacja)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0a0d48-0e2d-4950-a388-b0ad490c1c8a",
   "metadata": {},
   "source": [
    "#### Implementacja"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6cd2577-3bd6-4e78-8e1c-916b159c252a",
   "metadata": {},
   "source": [
    "```python\n",
    "import os\n",
    "import re\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Inicjalizacja listy stopping words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Funkcja do wczytywania e-maili i ich przetwarzania\n",
    "def preprocess_email(email_content):\n",
    "    # Usunięcie znaków interpunkcyjnych i konwersja na małe litery\n",
    "    email_body = re.sub(r'[^\\w\\s]', '', email_content).lower()\n",
    "    # Tokenizacja\n",
    "    tokens = word_tokenize(email_body)\n",
    "    # Usunięcie stopping words\n",
    "    filtered_tokens = [word for word in tokens if word not in stop_words]\n",
    "    return ' '.join(filtered_tokens)\n",
    "\n",
    "# Funkcja do wczytywania etykiet\n",
    "def load_labels(label_file_path):\n",
    "    labels = {}\n",
    "    with open(label_file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            label, message_path = line.strip().split(' ')\n",
    "            message_id = os.path.basename(message_path)\n",
    "            labels[message_id] = 0 if label == 'ham' else 1\n",
    "    return labels\n",
    "\n",
    "# Ścieżki do folderów i plików\n",
    "data_dir = 'trec07p/data'\n",
    "index_file = 'trec07p/full/index'\n",
    "\n",
    "# Wczytanie etykiet\n",
    "labels = load_labels(index_file)\n",
    "\n",
    "# Wczytanie i przetwarzanie e-maili\n",
    "emails = []\n",
    "y = []\n",
    "for file_name in os.listdir(data_dir):\n",
    "    file_path = os.path.join(data_dir, file_name)\n",
    "    if file_name in labels:\n",
    "        with open(file_path, 'r', encoding='utf-8', errors='ignore') as file:\n",
    "            email_content = file.read()\n",
    "        emails.append(preprocess_email(email_content))\n",
    "        y.append(labels[file_name])\n",
    "\n",
    "# Tworzenie wektora cech za pomocą CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(emails)\n",
    "\n",
    "# Podział na zbiory treningowy i testowy\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Klasyfikacja za pomocą MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Ewaluacja modelu\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f'Macierz konfuzji:\\n{cm}')\n",
    "print(f'Wartość wskaźnika accuracy: {acc * 100:.2f}%')\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625f4b74-c7d7-473c-8a01-43f4d3df3e57",
   "metadata": {},
   "source": [
    "#### Wyniki\n",
    "\n",
    "Macierz konfuzji:\n",
    "[[ 4990    12]\n",
    " [   74 10008]]\n",
    "Wartość wskaźnika accuracy: 99.43%\n",
    "\n",
    "#### Podsumowanie\n",
    "\n",
    "Zaimplementowany algorytm Naive Bayes wykazał wysoką skuteczność w klasyfikacji wiadomości e-mail. Skuteczność modelu, wyrażona wartością accuracy na poziomie 99.43%, jest znacząco wyższa w porównaniu do wyników z poprzednich zadań, co może wynikać z precyzyjnego dopasowania cech wejściowych i skuteczności algorytmu MultinomialNB w analizie tekstu. Niska liczba fałszywie pozytywnych i negatywnych wyników pokazuje, że model jest bardzo skuteczny w różnicowaniu spamu od wiadomości pożądanych.\n",
    "\n",
    "Model Naive Bayes, działający na danych przetworzonych z usunięciem słów przestankowych i zastosowaniem stemizacji, pokazał, że właściwe przygotowanie danych może znacznie zwiększyć skuteczność klasyfikacji, co jest istotnym wnioskiem dla przyszłych projektów związanych z filtrowaniem spamu."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955d3cf0-ec6b-489a-af0d-72b2d4fe2986",
   "metadata": {},
   "source": [
    "### Zadanie 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861c3559-b298-4adc-aaa0-b2d3d96bc106",
   "metadata": {},
   "source": [
    "> Dokonać klasyfikacji binarnej wiadomości z archiwum (zadanie 1) na spam i ham, stosując model gęsto łączonej głębokiej\n",
    "sieci neuronowej i technikę uczenia nadzorowanego.\n",
    "Uwagi:\n",
    "> 1. Zaproponować sposób translacji danych wejściowych do postaci akceptowanego przez sieć tensora wejściowego.\n",
    "> 2. Zaproponować liczbę warstw ukrytych oraz liczbę węzłów w poszczególnych warstwach.\n",
    "> 3. Zaproponować funkcje aktywacji dla węzłów w warstwach ukrytych oraz w warstwie wyjściowej.\n",
    "> 4. Zaproponować metrykę dokładności.\n",
    "> 5. Zaproponować optymalizator.\n",
    "> 6. Do realizacji zadania zastosować narzędzia z biblioteki TensorFLow.\n",
    "> 7. W wyniku realizacji zadania wygenerować macierz konfuzji oraz wartość wskaźnika accuracy.\n",
    "> 8. Porównać uzyskane wyniki dla różnych modeli (to znaczy: ilości warstw ukrytych, ilości węzłów w warstwach,\n",
    "funkcji aktywacji).\n",
    "> 9. Porównać uzyskane wyniki z wynikami uzyskanym w ramach realizacji poprzednich zadań."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadba013-1b40-4643-9435-0195b50bb8f1",
   "metadata": {},
   "source": [
    "Zadanie 6 koncentruje się na klasyfikacji binarnej wiadomości e-mail na spam i ham przy użyciu gęsto łączonej głębokiej sieci neuronowej w ramach techniki uczenia nadzorowanego. Wykorzystano narzędzia z biblioteki TensorFlow do zbudowania i trenowania modelu, a także do przekształcenia danych wejściowych w odpowiedni format tensora."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abe38da-dc7d-4665-a0ec-55f3e6e4b782",
   "metadata": {},
   "source": [
    "#### Implementacja"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b318c205-a2ef-4a7c-9e0a-08a466b83470",
   "metadata": {},
   "source": [
    "```python\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "# Inicjalizacja listy stopping words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "\n",
    "# Funkcja do wczytywania e-maili i ich przetwarzania\n",
    "def preprocess_email(email_text):\n",
    "    # Usunięcie znaków interpunkcyjnych i konwersja na małe litery\n",
    "    email_body = re.sub(r'[^\\w\\s]', '', email_text).lower()\n",
    "    # Tokenizacja\n",
    "    tokens = word_tokenize(email_body)\n",
    "    # Usunięcie stopping words\n",
    "    filtered_tokens = [word for word in tokens if word not in stop_words]\n",
    "    return ' '.join(filtered_tokens)\n",
    "\n",
    "\n",
    "# Funkcja do wczytywania etykiet\n",
    "def load_labels(label_file_path):\n",
    "    email_labels = {}\n",
    "    with open(label_file_path, 'r') as label_file:\n",
    "        for line in label_file:\n",
    "            label, message_path = line.strip().split(' ')\n",
    "            message_id = os.path.basename(message_path)\n",
    "            email_labels[message_id] = 0 if label == 'ham' else 1\n",
    "    return email_labels\n",
    "\n",
    "\n",
    "# Ścieżki do folderów i plików\n",
    "data_dir = 'trec07p/data'\n",
    "index_file = 'trec07p/full/index'\n",
    "\n",
    "# Wczytanie etykiet\n",
    "email_labels = load_labels(index_file)\n",
    "\n",
    "# Wczytanie i przetwarzanie e-maili\n",
    "emails = []\n",
    "labels = []\n",
    "for file_name in os.listdir(data_dir):\n",
    "    file_path = os.path.join(data_dir, file_name)\n",
    "    if file_name in email_labels:\n",
    "        with open(file_path, 'r', encoding='utf-8', errors='ignore') as email_file:\n",
    "            email_text = email_file.read()\n",
    "        emails.append(preprocess_email(email_text))\n",
    "        labels.append(email_labels[file_name])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74a9519-3bc0-4bf2-9498-7c09a6e5c296",
   "metadata": {},
   "source": [
    "    - Tokenizer: Tworzy słownik 10,000 najczęstszych słów w zbiorze danych, gdzie każde słowo jest mapowane na unikalny indeks.\n",
    "    - OOV Token: Określa token używany dla słów, które nie znajdują się w słowniku (Out of Vocabulary).\n",
    "    - fit_on_texts: Buduje słownik słów na podstawie dostarczonych tekstów.\n",
    "    - texts_to_sequences: Przekształca każdy email na sekwencję indeksów słów.\n",
    "    - pad_sequences: Standaryzuje długości sekwencji poprzez dodanie zer na końcu do osiągnięcia maksymalnej długości sekwencji 250."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e996261-f882-4e48-8e09-05722f5fbeaf",
   "metadata": {},
   "source": [
    "```python\n",
    "# Tokenizacja i padding sekwencji\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=10000, oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(emails)\n",
    "sequences = tokenizer.texts_to_sequences(emails)\n",
    "padded_sequences = tf.keras.utils.pad_sequences(sequences, maxlen=250, padding='post', truncating='post')\n",
    "\n",
    "# Podział na zbiory treningowy i testowy\n",
    "X_train, X_test, y_train, y_test = train_test_split(padded_sequences, np.array(labels), test_size=0.2, random_state=42)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d441b8-019d-4f81-9a94-d316c7e584df",
   "metadata": {},
   "source": [
    "Zastosowanie modelu sieci neuronowej z warstwami specyficznymi dla przetwarzania języka naturalnego:\n",
    "\n",
    "    - Embedding: Warstwa przekształcająca indeksy słów na gęste wektory cech. Jest to kluczowa warstwa w przetwarzaniu tekstów, pozwalająca na modelowanie złożonych zależności między słowami.\n",
    "    - GlobalAveragePooling1D: Redukuje wymiarowość przestrzeni cech, uśredniając wektory cech po wszystkich wymiarach sekwencji, co pozwala na obsługę różnych długości danych wejściowych.\n",
    "    - Dense: Typowe warstwy sieci gęsto połączonej, gdzie 24 oznacza liczbę neuronów, a relu jest funkcją aktywacji. Druga warstwa Dense pełni funkcję wyjściową z jednym neuronem i sigmoidalną funkcją aktywacji, przewidując prawdopodobieństwo przynależności do klasy 1 (spam)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f333d999-c69a-4051-927b-01ef12bdd68c",
   "metadata": {},
   "source": [
    "```python\n",
    "# Budowa modelu\n",
    "model = tf.keras.Sequential([\n",
    "    Embedding(10000, 16, input_length=250),\n",
    "    GlobalAveragePooling1D(),\n",
    "    Dense(24, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Trenowanie modelu\n",
    "model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test), verbose=2)\n",
    "\n",
    "# Ewaluacja modelu\n",
    "predictions = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "acc = accuracy_score(y_test, predictions)\n",
    "\n",
    "print(f'Macierz konfuzji:\\n{cm}')\n",
    "print(f'Wartość wskaźnika accuracy: {acc * 100:.2f}%')\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38d2a8b-012f-4acd-876e-f4eb91dd282e",
   "metadata": {},
   "source": [
    "#### Wyniki\n",
    "\n",
    "Epoch 1/10  \n",
    "1886/1886 - 14s - 7ms/step - accuracy: 0.9765 - loss: 0.0630 - val_accuracy: 0.9975 - val_loss: 0.0095  \n",
    "Epoch 2/10  \n",
    "1886/1886 - 12s - 7ms/step - accuracy: 0.9980 - loss: 0.0063 - val_accuracy: 0.9982 - val_loss: 0.0049  \n",
    "Epoch 3/10  \n",
    "1886/1886 - 12s - 7ms/step - accuracy: 0.9988 - loss: 0.0039 - val_accuracy: 0.9981 - val_loss: 0.0056  \n",
    "Epoch 4/10  \n",
    "1886/1886 - 13s - 7ms/step - accuracy: 0.9992 - loss: 0.0029 - val_accuracy: 0.9987 - val_loss: 0.0044  \n",
    "Epoch 5/10  \n",
    "1886/1886 - 12s - 7ms/step - accuracy: 0.9992 - loss: 0.0026 - val_accuracy: 0.9984 - val_loss: 0.0043  \n",
    "Epoch 6/10  \n",
    "1886/1886 - 13s - 7ms/step - accuracy: 0.9993 - loss: 0.0024 - val_accuracy: 0.9985 - val_loss: 0.0040  \n",
    "Epoch 7/10  \n",
    "1886/1886 - 13s - 7ms/step - accuracy: 0.9995 - loss: 0.0020 - val_accuracy: 0.9986 - val_loss: 0.0043  \n",
    "Epoch 8/10   \n",
    "1886/1886 - 13s - 7ms/step - accuracy: 0.9995 - loss: 0.0018 - val_accuracy: 0.9981 - val_loss: 0.0069  \n",
    "Epoch 9/10  \n",
    "1886/1886 - 13s - 7ms/step - accuracy: 0.9994 - loss: 0.0019 - val_accuracy: 0.9980 - val_loss: 0.0085  \n",
    "Epoch 10/10  \n",
    "1886/1886 - 13s - 7ms/step - accuracy: 0.9995 - loss: 0.0017 - val_accuracy: 0.9983 - val_loss: 0.0069  \n",
    "472/472 ━━━━━━━━━━━━━━━━━━━━ 1s 1ms/step  \n",
    "\n",
    "Macierz konfuzji:\n",
    "[[ 4979    23]\n",
    " [    2 10080]]\n",
    "Wartość wskaźnika accuracy: 99.83%\n",
    " \n",
    "#### Podsumowanie\n",
    "\n",
    "Model głębokiej sieci neuronowej wykazał wyjątkową skuteczność w klasyfikacji wiadomości na spam i ham, osiągając bardzo wysoki wskaźnik accuracy na poziomie 99.83%. Niska liczba błędów zarówno typu I (fałszywie pozytywne) jak i typu II (fałszywie negatywne) podkreśla skuteczność modelu w filtracji spamu oraz poprawnym identyfikowaniu pożądanych wiadomości.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a7afba-901e-4869-bf30-74f8c6a1b300",
   "metadata": {},
   "source": [
    "### Podsumowanie wniosków z projektu\n",
    "\n",
    "Przez serię zadań dotyczących klasyfikacji wiadomości e-mail jako spam lub ham, zbadaliśmy różnorodne metody przetwarzania danych, techniki uczenia maszynowego, oraz głębokiego uczenia, każda z nich przyniosła unikalne wnioski i lekcje. Oto ogólne podsumowanie wszystkich podejść:\n",
    "\n",
    "1. Tradycyjne Metody Przetwarzania Tekstu\n",
    "\n",
    "Początkowe zadania skupiały się na tradycyjnych metodach klasyfikacji, takich jak Naive Bayes i techniki oparte na słowach kluczowych oraz stop words. Te metody, choć efektywne w wielu scenariuszach, często wymagają starannej pre-selekcji cech i mogą mieć ograniczenia w kontekście interpretacji językowej i zrozumienia kontekstu.\n",
    "\n",
    "2. Zastosowanie Haszowania Rozmytego\n",
    "\n",
    "Wprowadzenie Locality-Sensitive Hashing (LSH) do klasyfikacji e-maili pozwoliło na eksplorację bardziej zaawansowanych technik identyfikacji podobieństwa między dokumentami. Mimo że metoda ta jest skuteczna w grupowaniu podobnych elementów, jej skuteczność w bezpośredniej klasyfikacji może być zależna od odpowiedniego doboru parametrów, takich jak próg podobieństwa.\n",
    "\n",
    "3. Głębokie Sieci Neuronowe\n",
    "\n",
    "Zastosowanie głębokich sieci neuronowych znacząco poprawiło wyniki klasyfikacji, umożliwiając modelom uczącym się na poziomie sekwencji słów uwzględnianie złożonych zależności kontekstowych i semantycznych. Metody te, choć wymagają większej mocy obliczeniowej i czasu na trening, oferują wysoką precyzję i są coraz częściej wybierane w nowoczesnych aplikacjach przetwarzania języka naturalnego.\n",
    "\n",
    "4. Porównanie i Konkluzje\n",
    "\n",
    "Porównanie różnych modeli i technik pokazało, że nie ma jednego najlepszego rozwiązania dla każdego scenariusza. Tradycyjne metody są szybkie i mniej złożone do implementacji, ale mogą nie radzić sobie dobrze z bardziej złożonymi problemami językowymi. Z kolei głębokie uczenie, choć efektywne, wymaga starannego doboru architektury i hiperparametrów. Wyniki eksperymentów z różnymi podejściami pokazały, że najlepsze rozwiązanie często wymaga hybrydowego podejścia lub wyboru metody dopasowanej do specyficznych wymagań danego problemu i dostępnych zasobów.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
